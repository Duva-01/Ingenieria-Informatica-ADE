{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen Adelantado Econometría 2020-2021\n",
    "## 12 de Enero de 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instrucciones\n",
    "\n",
    "+ La duración del examen de 1.5 horas.\n",
    "+ Cada pregunta se responderá en el recuadro bajo la pregunta, bien en modo sólo texto (Preguntas 1 a 5) o bien en modo códigos de Python + texto respuesta en base a los resultados obtenidos (Preguntas 6 a 10).\n",
    "+ Los datos necesarios está disponibles bien en la librería wooldridge o en el fichero Excel \"Pregunta7.xls\" que se encuentra en github (las órdenes orientativas para leer los ficheros se encuentran descritas bajo cada uno de esos ejercicios).\n",
    "+ No se evaluarán respuestas en las que únicamente haya códigos. Los resultados deberán servir para responder a las preguntas.\n",
    "+ Las puntuaciones de cada ejercicio se encuentran en el propio enunciado.\n",
    "+ El fichero final del examen se enviará a vía PRADO en la Tarea habilitada para el examen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### APELLIDOS,  NOMBRE: \n",
    "### DNI: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1: (1 punto)\n",
    "\n",
    "Justificar que $\\widehat{\\boldsymbol{\\beta}} \\sim N \\left( \\boldsymbol{\\beta}, \\ \\sigma^{2} \\cdot \\left( \\mathbf{X}^{t} \\mathbf{X} \\right)^{-1} \\right)$. ¿Qué supone este resultado cuando realizamos inferencia sobre los coeficientes de un modelo lineal múltiple?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: \n",
    "- En primer lugar, podemos saber que la Beta-hat sigue una distribucion Normal, ya que depende de una pertubacion aleatoria.\n",
    "- El hecho de que la esperanza de Beta-hat sea Beta, es porque de media nos equivocamos 0. \n",
    "  - En si la esperanza de y sin gorro es igual a la esperanza de y con gorro.\n",
    "- En cuanta a la varianza y debido a que las betas siguen una normal podemos establecer los intervalos de confianza y tambien podemos hacer lo test de significacion tanto global como individual por eso es imporante saber qeu cuando hacemos kolgomorov nos salga que sea normal porque sino no podemos hacer ninguna de estas estimaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2: (1 punto)\n",
    "\n",
    "Considera el modelo $Y_i = \\beta_0 + \\beta_1 X_i + u_i$ ($i=1,2,\\ldots,20$). Si realizamos la regresión de Mínimos Cuadrados Ordinarios de los residuos obtenidos en el modelo al cuadrado $u_i^2$ sobre las variables $X$ y $X^2$ (y la constante), obtenemos un $R^2$ de 0.35.  ¿Qué podemos decir sobre la homocedasticidad del modelo planteado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test de white (residuos al cuadrado) y (Glejser utiliza residuo con absoluto):\n",
    "  \n",
    "- Respuesta: Para poder hablar sobre la homocedasticidad necesitamos tener la informacion sobre la significacion global de los betas del modelo, para poder saber si los residuos dependen de las variables de las betas.\n",
    "- Sin embargo, como solo se nos da el R^2, no podemos concluir con ninguna respuesta.\n",
    "- Entonces se acabaria el supuesto basico de que los residios siguen una distribucion normal independiente de nuestras variables:\n",
    "\n",
    "- Mis residuos depende de mis X, (Y son mis residuos)\n",
    "- La X y la X^2 suspuestamente explica el 0.35 % los residuos, y tendriamos un problema de heterocedasticidad ya que no se puede explicar los residuos a traves de las variables.\n",
    "- Necesitamos hacer un test global de significacion para poder verificar la heterocedasticidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3: (0.75 puntos)\n",
    "\n",
    "Enumerar y describir brevemente la hipótesis básicas necesarias para realizar el análisis de un\n",
    "modelo de regresión lineal múltiple. Justificar las razones por las que se exigen cada una de\n",
    "estas hipótesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: Tema 2 principio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4: (0.5 puntos)\n",
    "\n",
    "En el caso de tener que decidir que modelo es el mejor en el siguiente caso:\n",
    "         \n",
    "            \\mbox{Modelo 1: } & & \\mathbf{Y} = \\beta_{1} + \\beta_{2} \\cdot \\mathbf{X}_{2} + \\beta_{3} \\cdot \\mathbf{X}_{3} + \\mathbf{u}. \\\\\n",
    "            \\mbox{Modelo 2: } & & \\mathbf{Y} = \\alpha_{1} + \\alpha_{2} \\cdot \\mathbf{X}_{2} + \\alpha_{3} \\cdot \\mathbf{X}_{3} + \\alpha_{4} \\cdot \\mathbf{X}_{4} + \\mathbf{v}\n",
    "        \n",
    "        ¿Qué herramientas usaría y con qué criterios? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: \n",
    "\n",
    "- A la hora de comprara dos modelos con la misma variable endogena podemos utilizar los R^2 para comparar los dos modelos, hay que tener en cuenta que los dos modelos son iguales, solo que el segundo modelo tiene una variable mas, lo que podria darnos casos de sobreestimacion del modelo.\n",
    "  \n",
    "- Por eso podriamos juzgarlos con el R^2 ajustado que penaliza el hecho de utilizar mas variables, ya que esto va a hacer que el R^2 vaya a ser mejor siempre pero el hecho de añadir variables por añadir podria dar ciertos problemas, de sobrestimacion del modelo, cambios en las significaciones individuales, incremento de multicolinealidad,etc...\n",
    "\n",
    "- En caso de que la variable endogena no fuese la misma, podriamos utilizar otros criterios de seleccion como el AIC (Akaike) y BIC (Schwarz).\n",
    "  \n",
    "- El modelo mas correcto seria el que tuviese mayor numero de variables, porque es el mejor lo explica porque va a tener un r-squared mayor.\n",
    "- Estimamos con los minimos cuadrados ordinario y comprobamos.\n",
    "- No necesariamente funciona con el r-squared, porque a veces se puede producir una sobreestimacion(que se utilicen un mayor numero de variables de las necesarias).\n",
    "- Lo correcto es utilizar el r-squared ajustado, porque este se ajusta al numero de variables que hay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5: (0.75 puntos)\n",
    "\n",
    "Consideremos un modelo económico en el que se desea explicar el precio de la vivienda en función de la zona donde se encuentra la vivienda, sus metros cuadrados, número de habitaciones, número de baños y si tiene o no cochera. Puesto que se sospecha que pudieran existir relaciones lineales entre los metros cuadrados de la vivienda y el número de baños y habitaciones de la misma, se calcula el factor de inflación de la varianza, obteniéndose que el mayor de ellos es igual a 4.78. ¿Se puede decir que el grado de multicolinealidad aproximada existente es preocupante? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: \n",
    "  \n",
    "  - El factor de inflacion de la varianza es un metodo muy comun para determinar si existe correlacion entre las variables, este se determina a raiz de una formula donde se encuentra involucrada R<sup>2</sup><sub>i</sub> como coeficiente de determinacion de la regresion X<sub>i</sub> sobre el resto de variables.\n",
    "  - Por lo que el vif se considera problematico a partir de 10, donde R<sup>2</sup><sub>i</sub> = 0.9 y habria que tenerlo en considereacion a partir de 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6: (1.5 puntos)\n",
    "\n",
    "Se desea analizar el número de becarios en la enseñanza universitaria, $\\mathbf{B}$ (medidos en miles), a partir del número de alumnos matriculados en los estudios de primer y segundo ciclo, $\\mathbf{A}$ (medidos en miles), y el importe destinado a becas, $\\mathbf{I}$ (medido en millones de euros). A partir de las universidades de las 17 comunidades autónomas más la universidad a distancia, se obtiene:\n",
    "        $$(\\mathbf{X}^{t} \\mathbf{X})^{-1} =  \\begin{pmatrix} 0.114 & -0.0005 & -0.0002 \\\\ -0.0005 & 0.00002 & -0.00002 \\\\ -0.0002 & -0.00002 & 0.00003 \\end{pmatrix}, \\mathbf{X}^{t} \\mathbf{y} = \n",
    "            \\begin{pmatrix}\n",
    "                443.818 \\\\\n",
    "         66792.89 \\\\\n",
    "                53125.748\n",
    "            \\end{pmatrix}, \\mathbf{y}^{t} \\mathbf{y} = 21953.5,$$\n",
    "            \n",
    "Se pide responder de forma razonada las siguientes cuestiones:\n",
    "1. Especificar los modelos económico y econométrico.\n",
    "1. Obtener la estimación de los coeficientes del modelo.\n",
    "1. ¿Es el coeficiente del número de alumnos matriculados en los estudios de primer y segundo ciclo significativamente distinto de cero al 95% de confianza? Indique las consecuencias del análisis realizado.\n",
    "1. Es el coeficiente del importe destinado a becas significativamente distinto de cero al 5% de significación? Indique las consecuencias del análisis realizado.\n",
    "1. Es el modelo globalmente significativo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta hat: \n",
      " [[6.5736574 ]\n",
      " [0.05143384]\n",
      " [0.16915104]]\n",
      "\n",
      "T teorica:  2.1199052992210112\n",
      "T experimental:  [0.56642664]\n",
      "Como nuestra t-experimental es menor que la t-teorica, por lo que no se rechaza y como puede tener el B[0] = 0, decimos que no tiene significacion individual\n",
      "\n",
      "T teorica:  2.1199052992210112\n",
      "T experimental:  [1.52098092]\n",
      "Como nuestra t-experimental es menor que la t-teorica, por lo que no se rechaza y como puede tener el B[0] = 0, decimos que no tiene significacion individual\n",
      "\n",
      "F teorica:  4.493998477666352\n",
      "F experimental:  [[10.66336752]]\n",
      "Como nuestra f-experimental es mayor que la f-teorica, por lo que se rechaza y no tiene significacion global\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#Cálculos:\n",
    "\n",
    "X_Trasp_X_Inversa = np.array([[0.114, -0.0005, -0.0002], [-0.0005, 0.00002, -0.00002], [-0.0002, -0.00002, 0.00003]])\n",
    "X_Trasp_y = np.array([[443.818], [66792.89], [53125.748]])\n",
    "\n",
    "Beta_hat = np.dot(X_Trasp_X_Inversa, X_Trasp_y)\n",
    "\n",
    "print(\"Beta hat: \\n\", Beta_hat)\n",
    "\n",
    "#--------------------------\n",
    "# Apartado 3\n",
    "# n numero de muestras = 18 y k numero de variables = 2\n",
    "# multiplicacion sacas 1 el n muestras\n",
    "\n",
    "n = 18\n",
    "k = 2\n",
    "\n",
    "scr = 21935.5 - np.dot(np.transpose(Beta_hat), X_Trasp_y)\n",
    "\n",
    "sigma_hat_sq = scr/(n-k)\n",
    "\n",
    "matriz_varianza_covarianza = sigma_hat_sq * X_Trasp_X_Inversa\n",
    "\n",
    "t_exp = np.absolute(Beta_hat[1]/np.sqrt(matriz_varianza_covarianza[1,1]))\n",
    "\n",
    "alpha=0.05\n",
    "t_teorica = stats.t.ppf(1-(alpha/2), n-k)\n",
    "\n",
    "print(\"\\nT teorica: \", t_teorica)\n",
    "print(\"T experimental: \", t_exp)\n",
    "print(\"Como nuestra t-experimental es menor que la t-teorica, por lo que no se rechaza y como puede tener el B[0] = 0, decimos que no tiene significacion individual\")\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Apartado 4\n",
    "\n",
    "t_exp = np.absolute(Beta_hat[2]/np.sqrt(matriz_varianza_covarianza[2,2]))\n",
    "\n",
    "print(\"\\nT teorica: \", t_teorica)\n",
    "print(\"T experimental: \", t_exp)\n",
    "print(\"Como nuestra t-experimental es menor que la t-teorica, por lo que no se rechaza y como puede tener el B[0] = 0, decimos que no tiene significacion individual\")\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Apartado 5\n",
    "# Xt*y la primera fila de esta es la sumatoria de todas las Y\n",
    "# Porque la fila de 1 la multiplicas por las Y\n",
    "\n",
    "sce = np.dot(np.transpose(Beta_hat), X_Trasp_y) - np.dot(n, (X_Trasp_y[0]/n)**2)\n",
    "scr = 21935.5 - np.dot(np.transpose(Beta_hat), X_Trasp_y)\n",
    "\n",
    "alpha=0.05\n",
    "f_exp = np.dot(((n-k)/(k-1)), sce/scr)\n",
    "f_teorica = stats.f.ppf(1-alpha, k-1, n-k)\n",
    "\n",
    "print(\"\\nF teorica: \", f_teorica)\n",
    "print(\"F experimental: \", f_exp)\n",
    "print(\"Como nuestra f-experimental es mayor que la f-teorica, por lo que se rechaza y no tiene significacion global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "  \n",
    "    --> Apartado a: \n",
    "\n",
    "        Modelo economico: B = Funcion(A,I)\n",
    "        Modelo econometrico: B = Beta[0] + Beta[1]*A + Beta[2]*I + u (residuos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 7: (1.5 puntos)\n",
    "\n",
    "Se considera el modelo econométrico $Y_i = \\beta_0 X_i^{\\beta_1} X_2^{\\beta_2} {\\rm exp}({u_i})$ $i=1, \\ldots, n$, donde $Y$ es la producción total de un bien, $X_1$ es el stock de capital, $X_2$ es el número de empleados para producir el bien y $u_i$ es la perturbación aleatoria. \n",
    "1. Transforma el modelo anterior en un modelo lineal múltiple.\n",
    "1. ¿Cómo se interpretarían los coeficientes del modelo? \n",
    "1. Que sentido tendría que $\\beta_1+\\beta_2=1$.\n",
    "1. Estima el modelo para los datos de \"Pregunta2.xls\", interpreta los coeficientes obtenidos y comprueba si $\\beta_1+\\beta_2=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de Beta[1]+Beta[2] = 1 -->  <F test: F=array([[0.19558359]]), p=0.6628307009409953, df_denom=21, df_num=1>\n",
      "Como el p-valor es > 0.05 decimos que el test se cumple\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.957\n",
      "Model:                            OLS   Adj. R-squared:                  0.953\n",
      "Method:                 Least Squares   F-statistic:                     236.1\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):           4.04e-15\n",
      "Time:                        19:48:32   Log-Likelihood:                 35.826\n",
      "No. Observations:                  24   AIC:                            -65.65\n",
      "Df Residuals:                      21   BIC:                            -62.12\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1773      0.434     -0.408      0.687      -1.080       0.726\n",
      "X1             0.2331      0.064      3.668      0.001       0.101       0.365\n",
      "X2             0.8073      0.145      5.565      0.000       0.506       1.109\n",
      "==============================================================================\n",
      "Omnibus:                        2.133   Durbin-Watson:                   1.523\n",
      "Prob(Omnibus):                  0.344   Jarque-Bera (JB):                1.361\n",
      "Skew:                           0.583   Prob(JB):                        0.506\n",
      "Kurtosis:                       2.992   Cond. No.                         285.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.957\n",
      "Model:                            OLS   Adj. R-squared:                  0.953\n",
      "Method:                 Least Squares   F-statistic:                     236.1\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):           4.04e-15\n",
      "Time:                        19:48:32   Log-Likelihood:                 35.826\n",
      "No. Observations:                  24   AIC:                            -65.65\n",
      "Df Residuals:                      21   BIC:                            -62.12\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1773      0.434     -0.408      0.687      -1.080       0.726\n",
      "X1             0.2331      0.064      3.668      0.001       0.101       0.365\n",
      "X2             0.8073      0.145      5.565      0.000       0.506       1.109\n",
      "==============================================================================\n",
      "Omnibus:                        2.133   Durbin-Watson:                   1.523\n",
      "Prob(Omnibus):                  0.344   Jarque-Bera (JB):                1.361\n",
      "Skew:                           0.583   Prob(JB):                        0.506\n",
      "Kurtosis:                       2.992   Cond. No.                         285.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "     Año   X1   X2    Y\n",
      "0   1899  100  100  100\n",
      "1   1900  107  105  101\n",
      "2   1901  114  110  112\n",
      "3   1902  122  118  122\n",
      "4   1903  131  123  124\n",
      "5   1904  138  116  122\n",
      "6   1905  149  125  143\n",
      "7   1906  163  133  152\n",
      "8   1907  176  138  151\n",
      "9   1908  185  121  126\n",
      "10  1909  198  140  155\n",
      "11  1910  208  144  159\n",
      "12  1911  216  145  153\n",
      "13  1912  226  152  177\n",
      "14  1913  236  154  184\n",
      "15  1914  244  149  169\n",
      "16  1915  266  154  189\n",
      "17  1916  298  182  225\n",
      "18  1917  335  196  227\n",
      "19  1918  366  200  223\n",
      "20  1919  387  193  218\n",
      "21  1920  407  193  231\n",
      "22  1921  417  147  179\n",
      "23  1922  431  161  240\n"
     ]
    }
   ],
   "source": [
    "#Cálculos:\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "from wooldridge import *\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.stats.api as sms\n",
    "from wooldridge import *\n",
    "import statsmodels.stats.outliers_influence as oi #Para el test RESET de Ramsey\n",
    "import statsmodels.stats.diagnostic as diagn #Para el test de Harvey-Collier\n",
    "import pandas as pd\n",
    "\n",
    "datos7 = pd.read_excel (\"Pregunta7.xls\")\n",
    "datos7_aux = pd.read_excel (\"Pregunta2.xls\")\n",
    "\n",
    "Y_LOG = np.log(datos7[\"Y\"])\n",
    "X_LOG = np.log(datos7[[\"X1\", \"X2\"]])\n",
    "\n",
    "\n",
    "Y_LOG2 = np.log(datos7_aux[\"Y\"])\n",
    "X_LOG2 = np.log(datos7_aux[[\"X1\", \"X2\"]])\n",
    "\n",
    "\n",
    "mco7 = sm.OLS(Y_LOG, sm.add_constant(X_LOG)).fit()\n",
    "mco7_2 = sm.OLS(Y_LOG2, sm.add_constant(X_LOG2)).fit()\n",
    "\n",
    "test = mco7.f_test(([0,1,1], [1]))\n",
    "print(\"Test de Beta[1]+Beta[2] = 1 --> \", test)\n",
    "print(\"Como el p-valor es > 0.05 decimos que el test se cumple\")\n",
    "print(mco7.summary())\n",
    "print(mco7_2.summary())\n",
    "print(datos7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: \n",
    "- Apartado a --> Aplicar logaritmos tanto en la y como en las x.\n",
    "- Apartado b --> Las variables significativas individualmente y su coeficiente implican el incremento de la Y... etc.\n",
    "- Apartado c --> El retorno constante de escalas, quiere decir que si aumentamos en uno cada una de las dos variables tambien sumaria en un 1% la Y.\n",
    "- Apartado d --> Los datos son iguales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 8: (1 punto)\n",
    "\n",
    "En la base de datos $\\texttt{phillips}$ se encuentra información para analizar el efecto del desempleo (unem) en el IPC (inf) desde 1948 a 2003. Estima el modelo lineal simple y estudia la existencia de autocorrelación en éste. En caso afirmativo, aplica alguna estrategia para corregirla y comprueba si ha concluido con éxito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    inf   R-squared:                       0.062\n",
      "Model:                            OLS   Adj. R-squared:                  0.045\n",
      "Method:                 Least Squares   F-statistic:                     3.579\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):             0.0639\n",
      "Time:                        19:48:32   Log-Likelihood:                -139.43\n",
      "No. Observations:                  56   AIC:                             282.9\n",
      "Df Residuals:                      54   BIC:                             286.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0536      1.548      0.681      0.499      -2.050       4.157\n",
      "unem           0.5024      0.266      1.892      0.064      -0.030       1.035\n",
      "==============================================================================\n",
      "Omnibus:                       13.468   Durbin-Watson:                   0.801\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.302\n",
      "Skew:                           1.138   Prob(JB):                     0.000784\n",
      "Kurtosis:                       3.976   Cond. No.                         23.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "DW:  0.8014823206513209 --> Problema de autocorrelacion\n"
     ]
    }
   ],
   "source": [
    "#Cálculos:\n",
    "from statsmodels.stats.stattools import durbin_watson #Si DW es 0, correlacion positiva, si es 4, correlacion negativa y si es 2 es incorrelaccionado, si no es alguno de esos valores me fijo en las tablas\n",
    "\n",
    "from wooldridge import *\n",
    "#dataWoo(\"phillips\", description=True)\n",
    "datos8=dataWoo(\"phillips\")\n",
    "\n",
    "Y = datos8[\"inf\"]\n",
    "X = datos8[[\"unem\"]]\n",
    "\n",
    "mco8 = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(mco8.summary())\n",
    "\n",
    "DW = durbin_watson(mco8.resid) #con el DW 0.066 tengo un problema de correlacion positiva\n",
    "print(\"DW: \", DW, \"--> Problema de autocorrelacion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5992588396743396\n",
      "Iterations used = 15 Converged True\n",
      "Rho =  [0.79650574]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLSAR Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>inf</td>       <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLSAR</td>      <th>  Adj. R-squared:    </th> <td>   0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0236</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:48:32</td>     <th>  Log-Likelihood:    </th> <td> -118.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    55</td>      <th>  AIC:               </th> <td>   241.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    53</td>      <th>  BIC:               </th> <td>   245.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.3837</td> <td>    2.224</td> <td>    3.321</td> <td> 0.002</td> <td>    2.924</td> <td>   11.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unem</th>  <td>   -0.6850</td> <td>    0.294</td> <td>   -2.331</td> <td> 0.024</td> <td>   -1.274</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.225</td> <th>  Durbin-Watson:     </th> <td>   1.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.010</td> <th>  Jarque-Bera (JB):  </th> <td>  19.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.230</td> <th>  Prob(JB):          </th> <td>5.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.897</td> <th>  Cond. No.          </th> <td>    12.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           GLSAR Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    inf   R-squared:                       0.093\n",
       "Model:                          GLSAR   Adj. R-squared:                  0.076\n",
       "Method:                 Least Squares   F-statistic:                     5.436\n",
       "Date:                Sun, 19 Dec 2021   Prob (F-statistic):             0.0236\n",
       "Time:                        19:48:32   Log-Likelihood:                -118.95\n",
       "No. Observations:                  55   AIC:                             241.9\n",
       "Df Residuals:                      53   BIC:                             245.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.3837      2.224      3.321      0.002       2.924      11.844\n",
       "unem          -0.6850      0.294     -2.331      0.024      -1.274      -0.096\n",
       "==============================================================================\n",
       "Omnibus:                        9.225   Durbin-Watson:                   1.626\n",
       "Prob(Omnibus):                  0.010   Jarque-Bera (JB):               19.725\n",
       "Skew:                          -0.230   Prob(JB):                     5.21e-05\n",
       "Kurtosis:                       5.897   Cond. No.                         12.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho= 1 - DW/2 # ro estimado inicial\n",
    "\n",
    "print (rho) # rho inicial\n",
    "mco_autocorr=sm.GLSAR(Y, sm.add_constant(X), rho=rho) # minimos cuadrados generalizados\n",
    "res = mco_autocorr.iterative_fit(maxiter=1000, rtol = 10**(-10)) # iteraciones y tolerancia, la tolerancia es si entre un rho y otro hay muy poca diferencia paro (10^-10)\n",
    "\n",
    "print ('Iterations used = %d Converged %s' % (res.iter, res.converged) )\n",
    "print ('Rho = ', mco_autocorr.rho)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: Corregido ez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 9: (1 punto)\n",
    "\n",
    "Comprueba la existencia de heteroscedasticidad en el modelo $\\log(price) = \\beta_0+ \\beta_1 \\log(lotsize)+\\log(sqrft)+bdrms$ usando los datos de $\\texttt{hprice1}$ utilizando el test de Breush-Pagan. ¿Qué consecuencias tendría en el análisis del modelo su existencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lprice   R-squared:                       0.635\n",
      "Model:                            OLS   Adj. R-squared:                  0.627\n",
      "Method:                 Least Squares   F-statistic:                     74.04\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):           2.41e-19\n",
      "Time:                        19:48:32   Log-Likelihood:                 24.927\n",
      "No. Observations:                  88   AIC:                            -43.85\n",
      "Df Residuals:                      85   BIC:                            -36.42\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.6401      0.602     -2.725      0.008      -2.837      -0.443\n",
      "llotsize       0.1685      0.038      4.380      0.000       0.092       0.245\n",
      "lsqrft         0.7624      0.081      9.425      0.000       0.602       0.923\n",
      "==============================================================================\n",
      "Omnibus:                        9.606   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):               23.727\n",
      "Skew:                          -0.006   Prob(JB):                     7.04e-06\n",
      "Kurtosis:                       5.544   Cond. No.                         360.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Cálculos:\n",
    "\n",
    "from wooldridge import *\n",
    "#dataWoo(\"hprice1\", description=True)\n",
    "datos9=dataWoo(\"hprice1\")\n",
    "\n",
    "Y=datos9[\"lprice\"]\n",
    "X=datos9[[\"llotsize\", \"lsqrft\"]]\n",
    "\n",
    "mco9 = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "print(mco9.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de breuschpagan: \n",
      "(1.5874830140307115, 0.4521499044970192, 0.7807668431560649, 0.46131150094548357) --> No tengo problema de heterocedasticidad, ya que mi p-valor > 0.05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BP = sms.het_breuschpagan(mco9.resid, mco9.model.exog)\n",
    "print(\"Test de breuschpagan: \")\n",
    "print(BP, \"--> No tengo problema de heterocedasticidad, ya que mi p-valor > 0.05 \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: Que las varianzas no sean iguales para todos los residuos.\n",
    "- Markov: insesgados, lineales y optimos pero como no tenemos heterocedasticidad, podemos decir que sean optimos (betas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 10: (1 punto)\n",
    "\n",
    "Se pretende analizar el efecto de los ingresos per cápita (pcinc), de la población (popul) y del número de médicos por cada 100 mil habitantes (physic) en la mortalidad infantil (infmrt), medida como el número de muertes infantiles por cada mil nacimientos vivos.\n",
    "1. Usando la base de datos $\\texttt{infmrt}$ para 1990, estima el modelo econométrico lineal usando los logaritmos de las variables exógenas e interpreta los resultados obtenidos.\n",
    "2. Analiza si existen diferencias significativas entre los resultados obtenidos para 1990 y para los de 1987."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                infmort   R-squared:                       0.182\n",
      "Model:                            OLS   Adj. R-squared:                  0.157\n",
      "Method:                 Least Squares   F-statistic:                     7.260\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):           0.000190\n",
      "Time:                        19:48:32   Log-Likelihood:                -207.70\n",
      "No. Observations:                 102   AIC:                             423.4\n",
      "Df Residuals:                      98   BIC:                             433.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         36.2261     10.135      3.574      0.001      16.114      56.338\n",
      "lpcinc        -4.8841      1.293     -3.777      0.000      -7.450      -2.318\n",
      "lpopul        -0.0536      0.187     -0.286      0.776      -0.426       0.318\n",
      "lphysic        4.0278      0.891      4.521      0.000       2.260       5.796\n",
      "==============================================================================\n",
      "Omnibus:                       28.943   Durbin-Watson:                   0.805\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.358\n",
      "Skew:                           1.062   Prob(JB):                     1.06e-14\n",
      "Kurtosis:                       6.261   Cond. No.                         745.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from wooldridge import *\n",
    "\n",
    "datos = dataWoo(\"infmrt\")\n",
    "Y=datos[\"infmort\"]\n",
    "X=datos[[\"lpcinc\", \"lpopul\", \"lphysic\"]]\n",
    "\n",
    "mco10 = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(mco10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                infmort   R-squared:                       0.139\n",
      "Model:                            OLS   Adj. R-squared:                  0.084\n",
      "Method:                 Least Squares   F-statistic:                     2.531\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):             0.0684\n",
      "Time:                        19:48:32   Log-Likelihood:                -107.09\n",
      "No. Observations:                  51   AIC:                             222.2\n",
      "Df Residuals:                      47   BIC:                             229.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         33.8593     20.428      1.658      0.104      -7.236      74.955\n",
      "lpcinc        -4.6847      2.604     -1.799      0.078      -9.923       0.554\n",
      "lpopul        -0.0878      0.287     -0.306      0.761      -0.666       0.490\n",
      "lphysic        4.1533      1.513      2.746      0.009       1.110       7.196\n",
      "==============================================================================\n",
      "Omnibus:                       19.635   Durbin-Watson:                   1.419\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.681\n",
      "Skew:                           1.114   Prob(JB):                     1.08e-08\n",
      "Kurtosis:                       6.507   Cond. No.                         982.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Cálculos:\n",
    "\n",
    "\n",
    "#dataWoo(\"infmrt\", description=True)\n",
    "datosPreg10=dataWoo(\"infmrt\")\n",
    "datos1990 = datosPreg10[datosPreg10[\"year\"] == 1990]\n",
    "\n",
    "Y=datos1990[\"infmort\"]\n",
    "X=datos1990[[\"lpcinc\", \"lpopul\", \"lphysic\"]]\n",
    "\n",
    "mco10_1990 = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(mco10_1990.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                infmort   R-squared:                       0.156\n",
      "Model:                            OLS   Adj. R-squared:                  0.102\n",
      "Method:                 Least Squares   F-statistic:                     2.891\n",
      "Date:                Sun, 19 Dec 2021   Prob (F-statistic):             0.0451\n",
      "Time:                        19:48:32   Log-Likelihood:                -100.05\n",
      "No. Observations:                  51   AIC:                             208.1\n",
      "Df Residuals:                      47   BIC:                             215.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         35.6619     16.160      2.207      0.032       3.153      68.171\n",
      "lpcinc        -4.6997      2.111     -2.227      0.031      -8.946      -0.454\n",
      "lpopul        -0.0218      0.253     -0.086      0.932      -0.531       0.487\n",
      "lphysic        3.7553      1.281      2.931      0.005       1.178       6.333\n",
      "==============================================================================\n",
      "Omnibus:                       12.950   Durbin-Watson:                   1.301\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               15.913\n",
      "Skew:                           0.911   Prob(JB):                     0.000350\n",
      "Kurtosis:                       5.041   Cond. No.                         882.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "datos1987 = datosPreg10[datosPreg10[\"year\"] == 1987]\n",
    "\n",
    "Y=datos1987[\"infmort\"]\n",
    "X=datos1987[[\"lpcinc\", \"lpopul\", \"lphysic\"]]\n",
    "\n",
    "mco10_1987 = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(mco10_1987.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La F-teorico:  2.4674936234496485\n",
      "La F-experimental:  0.06651624920314232\n",
      "No podemos rechazar la hipotesis nula, ya que nuestro f-teorico es mas grande que nuestra f-experimental, por lo que los coeficiente de 1990 y 1987 coinciden\n"
     ]
    }
   ],
   "source": [
    "scr1990=mco10_1990.ssr\n",
    "scr1987=mco10_1987.ssr\n",
    "scr = mco10.ssr\n",
    "n = mco10.nobs\n",
    "\n",
    "k=3\n",
    "\n",
    "alpha=0.05\n",
    "Fteo= stats.f.ppf(1-alpha,k+1,n-2*k-1)\n",
    "\n",
    "#Test de chow\n",
    "Fexp = ((n-(2*k)-2)/(k-1)) * ((scr-(scr1987+scr1990))/(scr1987+scr1990))\n",
    "\n",
    "print(\"La F-teorico: \", Fteo)\n",
    "print(\"La F-experimental: \", Fexp)\n",
    "\n",
    "print(\"No podemos rechazar la hipotesis nula, ya que nuestro f-teorico es mas grande que nuestra f-experimental, por lo que los coeficiente de 1990 y 1987 coinciden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: ez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
